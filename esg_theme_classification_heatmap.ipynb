{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ESG Theme Classification Heatmap Demo\n",
    "\n",
    "This notebook demonstrates how to classify ESG (Environmental, Social, Governance) themes in text and visualize the results as a heatmap."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Required Libraries\n",
    "\n",
    "This notebook requires the following libraries (install via requirements.txt):\n",
    "- spacy (with en_core_web_sm)\n",
    "- transformers\n",
    "- pandas\n",
    "- matplotlib\n",
    "- seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required dependencies\n",
    "\n",
    "# Jupyter Notebook interface for interactive computing\n",
    "%pip install notebook  \n",
    "\n",
    "# Natural language processing library for sentence segmentation\n",
    "%pip install spacy  \n",
    "\n",
    "# Hugging Face library for loading the ESG-BERT model\n",
    "%pip install transformers  \n",
    "\n",
    "# Deep learning backend required by transformers\n",
    "%pip install torch  \n",
    "\n",
    "# Data manipulation and analysis library\n",
    "%pip install pandas  \n",
    "\n",
    "# Core plotting library for creating visualizations\n",
    "%pip install matplotlib  \n",
    "\n",
    "# Advanced visualization library for heatmaps\n",
    "%pip install seaborn  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Document\n",
    "# Paste your CSR (Corporate Social Responsibility) report or similar text document below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"\"\"Example CSR report text. \n",
    "At GreenTech Solutions, we are committed to reducing our carbon emissions by 40% by 2030. As part of our environmental strategy, we have transitioned 60% of our fleet to electric vehicles and implemented solar panels across all office locations.\n",
    "\n",
    "We also believe in creating an inclusive and equitable workplace. Our diversity and inclusion committee has launched mentorship programs for underrepresented groups and revised hiring practices to reduce unconscious bias.\n",
    "\n",
    "To support local communities, we donated over $1 million to education and housing initiatives in 2024. Our employees volunteered more than 5,000 hours in various community outreach programs.\n",
    "\n",
    "In terms of governance, our board of directors has been expanded to include more independent members, with a focus on enhancing transparency and oversight. We've implemented a new whistleblower policy to ensure accountability at all levels of the organization.\n",
    "\n",
    "We continue to audit our supply chain to ensure ethical labour practices and environmental compliance. Regular risk assessments and stakeholder engagement ensure that we are aligned with best practices in corporate governance.\n",
    "\n",
    "Finally, as part of our sustainability goals, we've reduced water usage in our manufacturing processes by 25%, and we are targeting zero waste-to-landfill by 2026.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence Splitting with spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the spaCy English language model\n",
    "\n",
    "# Required for sentence segmentation\n",
    "!python -m spacy download en_core_web_sm  \n",
    "\n",
    "# Import the spaCy library\n",
    "import spacy\n",
    "\n",
    "# Load the English language model (small version)\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Process the input text with spaCy\n",
    "# This creates a Doc object with linguistic annotations\n",
    "doc = nlp(input_text)\n",
    "\n",
    "# Extract sentences using spaCy's sentence segmentation\n",
    "# spaCy identifies sentence boundaries based on punctuation and other linguistic features\n",
    "sentences = [sent.text.strip() for sent in doc.sents]\n",
    "\n",
    "# Print the list of sentences for verification\n",
    "print(f\"Found {len(sentences)} sentences:\")\n",
    "for i, sentence in enumerate(sentences, 1):\n",
    "    print(f\"{i}. {sentence}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ESG Classification with Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules from transformers and torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Load the pretrained ESG-BERT model and tokenizer from Hugging Face\n",
    "# This model is specifically trained to classify text into ESG categories\n",
    "model_name = \"nbroad/ESG-BERT\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Define a function to classify sentences into detailed ESG categories\n",
    "def classify_sentence(sentence):\n",
    "    \"\"\"\n",
    "    Classify a sentence into one of the 26 detailed ESG categories and map it to its main ESG pillar.\n",
    "    \n",
    "    Args:\n",
    "        sentence (str): The input sentence to classify\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (detailed_category_name, main_esg_pillar, confidence_score) where:\n",
    "               - detailed_category_name is the specific ESG category (e.g., \"GHG_Emissions\")\n",
    "               - main_esg_pillar is the high-level ESG category (\"Environmental\", \"Social\", or \"Governance\")\n",
    "               - confidence_score is the model's confidence in the prediction\n",
    "    \"\"\"\n",
    "    # Step 1: Tokenize the input sentence\n",
    "    # Convert the text into tokens that the model can understand\n",
    "    # return_tensors=\"pt\" returns PyTorch tensors\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    \n",
    "    # Step 2: Feed the tokenized sentence into the model to obtain raw logits\n",
    "    # Set model to evaluation mode and disable gradient calculation for inference\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "    \n",
    "    # Step 3: Apply softmax function to convert logits into probability distribution\n",
    "    # Softmax normalizes the logits so they sum to 1, representing probabilities\n",
    "    probabilities = F.softmax(logits, dim=1)\n",
    "    \n",
    "    # Get the predicted class (highest probability)\n",
    "    predicted_class = torch.argmax(probabilities, dim=1).item()\n",
    "    probability_value = probabilities[0][predicted_class].item()\n",
    "    \n",
    "    # Step 4: Map the predicted numerical label to detailed ESG categories\n",
    "    # This mapping is based on the SASB framework as specified in the task\n",
    "    detailed_categories = {\n",
    "        # Environmental Categories\n",
    "        13: \"Physical_Impacts_Of_Climate_Change\",\n",
    "        19: \"Waste_And_Hazardous_Materials_Management\",\n",
    "        20: \"Water_And_Wastewater_Management\",\n",
    "        21: \"Air_Quality\",\n",
    "        23: \"Ecological_Impacts\",\n",
    "        24: \"Energy_Management\",\n",
    "        25: \"GHG_Emissions\",\n",
    "        # Social Categories\n",
    "        1: \"Data_Security\",\n",
    "        2: \"Access_And_Affordability\",\n",
    "        6: \"Customer_Welfare\",\n",
    "        8: \"Employee_Engagement_Inclusion_And_Diversity\",\n",
    "        9: \"Employee_Health_And_Safety\",\n",
    "        10: \"Human_Rights_And_Community_Relations\",\n",
    "        11: \"Labor_Practices\",\n",
    "        14: \"Product_Quality_And_Safety\",\n",
    "        16: \"Selling_Practices_And_Product_Labeling\",\n",
    "        22: \"Customer_Privacy\",\n",
    "        # Governance Categories\n",
    "        0: \"Business_Ethics\",\n",
    "        3: \"Business_Model_Resilience\",\n",
    "        4: \"Competitive_Behavior\",\n",
    "        5: \"Critical_Incident_Risk_Management\",\n",
    "        7: \"Director_Removal\",\n",
    "        12: \"Management_Of_Legal_And_Regulatory_Framework\",\n",
    "        15: \"Product_Design_And_Lifecycle_Management\",\n",
    "        17: \"Supply_Chain_Management\",\n",
    "        18: \"Systemic_Risk_Management\"\n",
    "    }\n",
    "    \n",
    "    # Step 5: Map each detailed category to its main ESG pillar\n",
    "    # This grouping is based on the SASB framework as specified in the task\n",
    "    esg_pillars = {\n",
    "        # Environmental Categories\n",
    "        \"Physical_Impacts_Of_Climate_Change\": \"Environmental\",\n",
    "        \"Waste_And_Hazardous_Materials_Management\": \"Environmental\",\n",
    "        \"Water_And_Wastewater_Management\": \"Environmental\",\n",
    "        \"Air_Quality\": \"Environmental\",\n",
    "        \"Ecological_Impacts\": \"Environmental\",\n",
    "        \"Energy_Management\": \"Environmental\",\n",
    "        \"GHG_Emissions\": \"Environmental\",\n",
    "        # Social Categories\n",
    "        \"Data_Security\": \"Social\",\n",
    "        \"Access_And_Affordability\": \"Social\",\n",
    "        \"Customer_Welfare\": \"Social\",\n",
    "        \"Employee_Engagement_Inclusion_And_Diversity\": \"Social\",\n",
    "        \"Employee_Health_And_Safety\": \"Social\",\n",
    "        \"Human_Rights_And_Community_Relations\": \"Social\",\n",
    "        \"Labor_Practices\": \"Social\",\n",
    "        \"Product_Quality_And_Safety\": \"Social\",\n",
    "        \"Selling_Practices_And_Product_Labeling\": \"Social\",\n",
    "        \"Customer_Privacy\": \"Social\",\n",
    "        # Governance Categories\n",
    "        \"Business_Ethics\": \"Governance\",\n",
    "        \"Business_Model_Resilience\": \"Governance\",\n",
    "        \"Competitive_Behavior\": \"Governance\",\n",
    "        \"Critical_Incident_Risk_Management\": \"Governance\",\n",
    "        \"Director_Removal\": \"Governance\",\n",
    "        \"Management_Of_Legal_And_Regulatory_Framework\": \"Governance\",\n",
    "        \"Product_Design_And_Lifecycle_Management\": \"Governance\",\n",
    "        \"Supply_Chain_Management\": \"Governance\",\n",
    "        \"Systemic_Risk_Management\": \"Governance\"\n",
    "    }\n",
    "    \n",
    "    # Get the detailed category name\n",
    "    detailed_category = detailed_categories.get(predicted_class, f\"Unknown_Category_{predicted_class}\")\n",
    "    \n",
    "    # Get the main ESG pillar for this detailed category\n",
    "    main_pillar = esg_pillars.get(detailed_category, \"Unknown\")\n",
    "    \n",
    "    # Return the tuple with detailed category, main pillar, and confidence score\n",
    "    return detailed_category, main_pillar, probability_value\n",
    "\n",
    "# Test the function on a sample sentence\n",
    "sample_sentence = \"The company reduced carbon emissions by 15% this year.\"\n",
    "detailed_category, main_pillar, confidence = classify_sentence(sample_sentence)\n",
    "print(f\"Sample: '{sample_sentence}'\")\n",
    "print(f\"Detailed ESG Category: {detailed_category}\")\n",
    "print(f\"Main ESG Pillar: {main_pillar}\")\n",
    "print(f\"Confidence: {confidence:.4f} ({confidence*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregation of Classification Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas for data manipulation and analysis\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize counters for each ESG category\n",
    "# These will track how many sentences fall into each category\n",
    "environmental_count = 0\n",
    "social_count = 0\n",
    "governance_count = 0\n",
    "\n",
    "# Loop through each sentence in our list of sentences\n",
    "for sentence in sentences:\n",
    "    # Call the classify_sentence function to get the predicted ESG category\n",
    "    # This returns the detailed category, main pillar, and confidence score\n",
    "    _, main_pillar, _ = classify_sentence(sentence)\n",
    "    \n",
    "    # Increment the appropriate counter based on the predicted main pillar\n",
    "    if main_pillar == \"Environmental\":\n",
    "        environmental_count += 1\n",
    "    elif main_pillar == \"Social\":\n",
    "        social_count += 1\n",
    "    elif main_pillar == \"Governance\":\n",
    "        governance_count += 1\n",
    "\n",
    "# Create a dictionary with the counts for each category\n",
    "# This will be used to create our DataFrame\n",
    "esg_counts = {\n",
    "    \"Environmental\": [environmental_count],\n",
    "    \"Social\": [social_count],\n",
    "    \"Governance\": [governance_count]\n",
    "}\n",
    "\n",
    "# Create a pandas DataFrame with the counts\n",
    "# The index is set to \"Report\" to indicate these counts are for the entire document\n",
    "esg_df = pd.DataFrame(esg_counts, index=[\"Report\"])\n",
    "\n",
    "# Print the resulting DataFrame showing the distribution of ESG categories\n",
    "print(\"ESG Category Distribution:\")\n",
    "print(esg_df)\n",
    "\n",
    "# Calculate and print the total number of sentences classified\n",
    "total_sentences = environmental_count + social_count + governance_count\n",
    "print(f\"\\nTotal sentences classified: {total_sentences}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heatmap Visualization of ESG Classification Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import visualization libraries\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the figure size for better visualization\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "# Create a heatmap using Seaborn\n",
    "# - data: The DataFrame containing our ESG category counts\n",
    "# - annot=True: Display the numerical values in each cell\n",
    "# - cmap=\"YlGnBu\": Use the Yellow-Green-Blue color palette\n",
    "# - fmt=\"d\": Format annotations as integers (d = decimal integer)\n",
    "# - linewidths=.5: Add thin lines between cells for better separation\n",
    "# - cbar=True: Include a color bar legend\n",
    "ax = sns.heatmap(esg_df, \n",
    "                annot=True,        # Show the count values in each cell\n",
    "                cmap=\"YlGnBu\",     # Use the Yellow-Green-Blue color palette\n",
    "                fmt=\"d\",           # Format annotations as integers\n",
    "                linewidths=.5,     # Add thin lines between cells\n",
    "                cbar_kws={'label': 'Sentence Count'})  # Label the color bar\n",
    "\n",
    "# Set the title for the heatmap\n",
    "plt.title(\"ESG Theme Distribution in Report\", fontsize=14)\n",
    "\n",
    "# Customize the axis labels\n",
    "plt.xlabel(\"ESG Categories\", fontsize=12)\n",
    "plt.ylabel(\"Document\", fontsize=12)\n",
    "\n",
    "# Adjust layout to prevent clipping of labels\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the heatmap\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete Workflow: End-to-End ESG Classification and Visualization\n",
    "\n",
    "This cell integrates all the previous components into a complete workflow:\n",
    "1. Process the input text to extract individual sentences\n",
    "2. Classify each sentence into an ESG category (Environmental, Social, Governance)\n",
    "3. Aggregate the classification results into a structured DataFrame\n",
    "4. Visualize the distribution of ESG themes using a heatmap\n",
    "\n",
    "This workflow allows for quick analysis of ESG themes in corporate reports or other text documents,\n",
    "providing insights into the balance and emphasis of different sustainability aspects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Process the input text to split it into sentences\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(input_text)\n",
    "sentences = [sent.text.strip() for sent in doc.sents]\n",
    "print(f\"Processing {len(sentences)} sentences...\")\n",
    "\n",
    "# Step 2: Classify each sentence using the classify_sentence function\n",
    "# Initialize a list to store detailed results\n",
    "classification_results = []\n",
    "\n",
    "# Process each sentence\n",
    "for sentence in sentences:\n",
    "    detailed_category, main_pillar, confidence = classify_sentence(sentence)\n",
    "    classification_results.append({\n",
    "        'sentence': sentence,\n",
    "        'detailed_category': detailed_category,\n",
    "        'main_pillar': main_pillar,\n",
    "        'confidence': confidence\n",
    "    })\n",
    "    \n",
    "# Step 3: Aggregate the classification results into a Pandas DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "# Create a detailed DataFrame with all classification results\n",
    "results_df = pd.DataFrame(classification_results)\n",
    "\n",
    "# Count occurrences of each main pillar\n",
    "pillar_counts = results_df['main_pillar'].value_counts().to_dict()\n",
    "\n",
    "# Ensure all categories are represented (even if count is 0)\n",
    "esg_counts = {\n",
    "    \"Environmental\": pillar_counts.get(\"Environmental\", 0),\n",
    "    \"Social\": pillar_counts.get(\"Social\", 0),\n",
    "    \"Governance\": pillar_counts.get(\"Governance\", 0)\n",
    "}\n",
    "\n",
    "# Create the aggregated DataFrame for visualization\n",
    "esg_df = pd.DataFrame([esg_counts], index=[\"Report\"])\n",
    "\n",
    "# Display the aggregated results\n",
    "print(\"\\nESG Category Distribution:\")\n",
    "print(esg_df)\n",
    "\n",
    "# Also display the detailed category distribution\n",
    "print(\"\\nDetailed ESG Category Distribution:\")\n",
    "detailed_counts = results_df['detailed_category'].value_counts()\n",
    "print(detailed_counts)\n",
    "\n",
    "# Step 4: Generate and display the heatmap visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create the visualization\n",
    "plt.figure(figsize=(10, 4))\n",
    "ax = sns.heatmap(esg_df, \n",
    "                annot=True,\n",
    "                cmap=\"YlGnBu\",\n",
    "                fmt=\"d\",\n",
    "                linewidths=.5,\n",
    "                cbar_kws={'label': 'Sentence Count'})\n",
    "\n",
    "plt.title(\"ESG Theme Distribution in Report\", fontsize=14)\n",
    "plt.xlabel(\"ESG Categories\", fontsize=12)\n",
    "plt.ylabel(\"Document\", fontsize=12)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the final visualization\n",
    "plt.show()\n",
    "\n",
    "# Print a summary of the analysis\n",
    "print(\"\\nAnalysis Summary:\")\n",
    "print(f\"Total sentences analyzed: {len(sentences)}\")\n",
    "print(f\"Environmental themes: {esg_counts['Environmental']} sentences ({esg_counts['Environmental']/len(sentences)*100:.1f}%)\")\n",
    "print(f\"Social themes: {esg_counts['Social']} sentences ({esg_counts['Social']/len(sentences)*100:.1f}%)\")\n",
    "print(f\"Governance themes: {esg_counts['Governance']} sentences ({esg_counts['Governance']/len(sentences)*100:.1f}%)\")\n",
    "print(f\"Dominant theme: {max(esg_counts, key=esg_counts.get)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
