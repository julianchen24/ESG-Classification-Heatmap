{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ESG Theme Classification Heatmap Demo\n",
    "\n",
    "This notebook demonstrates how to classify ESG (Environmental, Social, Governance) themes in text and visualize the results as a heatmap."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Required Libraries\n",
    "\n",
    "This notebook requires the following libraries (install via requirements.txt):\n",
    "- spacy (with en_core_web_sm)\n",
    "- transformers\n",
    "- pandas\n",
    "- matplotlib\n",
    "- seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required dependencies\n",
    "%pip install notebook  # Jupyter Notebook interface for interactive computing\n",
    "%pip install spacy  # Natural language processing library for sentence segmentation\n",
    "%pip install transformers  # Hugging Face library for loading the ESG-BERT model\n",
    "%pip install torch  # Deep learning backend required by transformers\n",
    "%pip install pandas  # Data manipulation and analysis library\n",
    "%pip install matplotlib  # Core plotting library for creating visualizations\n",
    "%pip install seaborn  # Advanced visualization library for heatmaps\n",
    "\n",
    "# Download the spaCy English language model\n",
    "!python -m spacy download en_core_web_sm  # Required for sentence segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Document\n",
    "# Paste your CSR (Corporate Social Responsibility) report or similar text document below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"\"\"Example CSR report text. \n",
    "At GreenTech Solutions, we are committed to reducing our carbon emissions by 40% by 2030. As part of our environmental strategy, we have transitioned 60% of our fleet to electric vehicles and implemented solar panels across all office locations.\n",
    "\n",
    "We also believe in creating an inclusive and equitable workplace. Our diversity and inclusion committee has launched mentorship programs for underrepresented groups and revised hiring practices to reduce unconscious bias.\n",
    "\n",
    "To support local communities, we donated over $1 million to education and housing initiatives in 2024. Our employees volunteered more than 5,000 hours in various community outreach programs.\n",
    "\n",
    "In terms of governance, our board of directors has been expanded to include more independent members, with a focus on enhancing transparency and oversight. We've implemented a new whistleblower policy to ensure accountability at all levels of the organization.\n",
    "\n",
    "We continue to audit our supply chain to ensure ethical labour practices and environmental compliance. Regular risk assessments and stakeholder engagement ensure that we are aligned with best practices in corporate governance.\n",
    "\n",
    "Finally, as part of our sustainability goals, we've reduced water usage in our manufacturing processes by 25%, and we are targeting zero waste-to-landfill by 2026.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence Splitting with spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Import the spaCy library\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mspacy\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Load the English language model (small version)\u001b[39;00m\n\u001b[32m      5\u001b[39m nlp = spacy.load(\u001b[33m\"\u001b[39m\u001b[33men_core_web_sm\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "# Import the spaCy library\n",
    "import spacy\n",
    "\n",
    "# Load the English language model (small version)\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Process the input text with spaCy\n",
    "# This creates a Doc object with linguistic annotations\n",
    "doc = nlp(input_text)\n",
    "\n",
    "# Extract sentences using spaCy's sentence segmentation\n",
    "# spaCy identifies sentence boundaries based on punctuation and other linguistic features\n",
    "sentences = [sent.text.strip() for sent in doc.sents]\n",
    "\n",
    "# Print the list of sentences for verification\n",
    "print(f\"Found {len(sentences)} sentences:\")\n",
    "for i, sentence in enumerate(sentences, 1):\n",
    "    print(f\"{i}. {sentence}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ESG Classification with Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules from transformers and torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Load the pretrained ESG-BERT model and tokenizer from Hugging Face\n",
    "# This model is specifically trained to classify text into ESG categories\n",
    "model_name = \"nbroad/ESG-BERT\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Define a function to classify sentences into ESG categories\n",
    "def classify_sentence(sentence):\n",
    "    \"\"\"\n",
    "    Classify a sentence into one of the ESG (Environmental, Social, Governance) categories.\n",
    "    \n",
    "    Args:\n",
    "        sentence (str): The input sentence to classify\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (category_name, probability) where category_name is the predicted ESG category\n",
    "               and probability is the confidence score for that prediction\n",
    "    \"\"\"\n",
    "    # Step 1: Tokenize the input sentence\n",
    "    # Convert the text into tokens that the model can understand\n",
    "    # return_tensors=\"pt\" returns PyTorch tensors\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    \n",
    "    # Step 2: Feed the tokenized sentence into the model to obtain raw logits\n",
    "    # Set model to evaluation mode and disable gradient calculation for inference\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "    \n",
    "    # Step 3: Apply softmax function to convert logits into probability distribution\n",
    "    # Softmax normalizes the logits so they sum to 1, representing probabilities\n",
    "    probabilities = F.softmax(logits, dim=1)\n",
    "    \n",
    "    # Get the predicted class (highest probability)\n",
    "    predicted_class = torch.argmax(probabilities, dim=1).item()\n",
    "    probability_value = probabilities[0][predicted_class].item()\n",
    "    \n",
    "    # Step 4: Map the predicted numerical label to ESG categories\n",
    "    # The mapping depends on how the model was trained\n",
    "    # For ESG-BERT, typically: 0=Environmental, 1=Social, 2=Governance\n",
    "    esg_categories = {\n",
    "        0: \"Environmental\",\n",
    "        1: \"Social\",\n",
    "        2: \"Governance\"\n",
    "    }\n",
    "    \n",
    "    category = esg_categories[predicted_class]\n",
    "    \n",
    "    return category, probability_value\n",
    "\n",
    "# Test the function on a sample sentence\n",
    "sample_sentence = \"The company reduced carbon emissions by 15% this year.\"\n",
    "category, confidence = classify_sentence(sample_sentence)\n",
    "print(f\"Sample: '{sample_sentence}'\")\n",
    "print(f\"Predicted ESG Category: {category}\")\n",
    "print(f\"Confidence: {confidence:.4f} ({confidence*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregation of Classification Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas for data manipulation and analysis\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize counters for each ESG category\n",
    "# These will track how many sentences fall into each category\n",
    "environmental_count = 0\n",
    "social_count = 0\n",
    "governance_count = 0\n",
    "\n",
    "# Loop through each sentence in our list of sentences\n",
    "for sentence in sentences:\n",
    "    # Call the classify_sentence function to get the predicted ESG category\n",
    "    # This returns both the category name and the confidence score\n",
    "    category, confidence = classify_sentence(sentence)\n",
    "    \n",
    "    # Increment the appropriate counter based on the predicted category\n",
    "    if category == \"Environmental\":\n",
    "        environmental_count += 1\n",
    "    elif category == \"Social\":\n",
    "        social_count += 1\n",
    "    elif category == \"Governance\":\n",
    "        governance_count += 1\n",
    "\n",
    "# Create a dictionary with the counts for each category\n",
    "# This will be used to create our DataFrame\n",
    "esg_counts = {\n",
    "    \"Environmental\": [environmental_count],\n",
    "    \"Social\": [social_count],\n",
    "    \"Governance\": [governance_count]\n",
    "}\n",
    "\n",
    "# Create a pandas DataFrame with the counts\n",
    "# The index is set to \"Report\" to indicate these counts are for the entire document\n",
    "esg_df = pd.DataFrame(esg_counts, index=[\"Report\"])\n",
    "\n",
    "# Print the resulting DataFrame showing the distribution of ESG categories\n",
    "print(\"ESG Category Distribution:\")\n",
    "print(esg_df)\n",
    "\n",
    "# Calculate and print the total number of sentences classified\n",
    "total_sentences = environmental_count + social_count + governance_count\n",
    "print(f\"\\nTotal sentences classified: {total_sentences}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heatmap Visualization of ESG Classification Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import visualization libraries\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the figure size for better visualization\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "# Create a heatmap using Seaborn\n",
    "# - data: The DataFrame containing our ESG category counts\n",
    "# - annot=True: Display the numerical values in each cell\n",
    "# - cmap=\"YlGnBu\": Use the Yellow-Green-Blue color palette\n",
    "# - fmt=\"d\": Format annotations as integers (d = decimal integer)\n",
    "# - linewidths=.5: Add thin lines between cells for better separation\n",
    "# - cbar=True: Include a color bar legend\n",
    "ax = sns.heatmap(esg_df, \n",
    "                annot=True,        # Show the count values in each cell\n",
    "                cmap=\"YlGnBu\",     # Use the Yellow-Green-Blue color palette\n",
    "                fmt=\"d\",           # Format annotations as integers\n",
    "                linewidths=.5,     # Add thin lines between cells\n",
    "                cbar_kws={'label': 'Sentence Count'})  # Label the color bar\n",
    "\n",
    "# Set the title for the heatmap\n",
    "plt.title(\"ESG Theme Distribution in Report\", fontsize=14)\n",
    "\n",
    "# Customize the axis labels\n",
    "plt.xlabel(\"ESG Categories\", fontsize=12)\n",
    "plt.ylabel(\"Document\", fontsize=12)\n",
    "\n",
    "# Adjust layout to prevent clipping of labels\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the heatmap\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete Workflow: End-to-End ESG Classification and Visualization\n",
    "\n",
    "This cell integrates all the previous components into a complete workflow:\n",
    "1. Process the input text to extract individual sentences\n",
    "2. Classify each sentence into an ESG category (Environmental, Social, Governance)\n",
    "3. Aggregate the classification results into a structured DataFrame\n",
    "4. Visualize the distribution of ESG themes using a heatmap\n",
    "\n",
    "This workflow allows for quick analysis of ESG themes in corporate reports or other text documents,\n",
    "providing insights into the balance and emphasis of different sustainability aspects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Process the input text to split it into sentences\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(input_text)\n",
    "sentences = [sent.text.strip() for sent in doc.sents]\n",
    "print(f\"Processing {len(sentences)} sentences...\")\n",
    "\n",
    "# Step 2: Classify each sentence using the classify_sentence function\n",
    "# Initialize a list to store detailed results\n",
    "classification_results = []\n",
    "\n",
    "# Process each sentence\n",
    "for sentence in sentences:\n",
    "    category, confidence = classify_sentence(sentence)\n",
    "    classification_results.append({\n",
    "        'sentence': sentence,\n",
    "        'category': category,\n",
    "        'confidence': confidence\n",
    "    })\n",
    "    \n",
    "# Step 3: Aggregate the classification results into a Pandas DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "# Create a detailed DataFrame with all classification results\n",
    "results_df = pd.DataFrame(classification_results)\n",
    "\n",
    "# Count occurrences of each category\n",
    "category_counts = results_df['category'].value_counts().to_dict()\n",
    "\n",
    "# Ensure all categories are represented (even if count is 0)\n",
    "esg_counts = {\n",
    "    \"Environmental\": category_counts.get(\"Environmental\", 0),\n",
    "    \"Social\": category_counts.get(\"Social\", 0),\n",
    "    \"Governance\": category_counts.get(\"Governance\", 0)\n",
    "}\n",
    "\n",
    "# Create the aggregated DataFrame for visualization\n",
    "esg_df = pd.DataFrame([esg_counts], index=[\"Report\"])\n",
    "\n",
    "# Display the aggregated results\n",
    "print(\"\\nESG Category Distribution:\")\n",
    "print(esg_df)\n",
    "\n",
    "# Step 4: Generate and display the heatmap visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create the visualization\n",
    "plt.figure(figsize=(10, 4))\n",
    "ax = sns.heatmap(esg_df, \n",
    "                annot=True,\n",
    "                cmap=\"YlGnBu\",\n",
    "                fmt=\"d\",\n",
    "                linewidths=.5,\n",
    "                cbar_kws={'label': 'Sentence Count'})\n",
    "\n",
    "plt.title(\"ESG Theme Distribution in Report\", fontsize=14)\n",
    "plt.xlabel(\"ESG Categories\", fontsize=12)\n",
    "plt.ylabel(\"Document\", fontsize=12)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the final visualization\n",
    "plt.show()\n",
    "\n",
    "# Print a summary of the analysis\n",
    "print(\"\\nAnalysis Summary:\")\n",
    "print(f\"Total sentences analyzed: {len(sentences)}\")\n",
    "print(f\"Environmental themes: {esg_counts['Environmental']} sentences ({esg_counts['Environmental']/len(sentences)*100:.1f}%)\")\n",
    "print(f\"Social themes: {esg_counts['Social']} sentences ({esg_counts['Social']/len(sentences)*100:.1f}%)\")\n",
    "print(f\"Governance themes: {esg_counts['Governance']} sentences ({esg_counts['Governance']/len(sentences)*100:.1f}%)\")\n",
    "print(f\"Dominant theme: {max(esg_counts, key=esg_counts.get)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
